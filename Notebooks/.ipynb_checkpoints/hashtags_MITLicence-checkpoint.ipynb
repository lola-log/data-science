{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstagramScrapper:\n",
    "    def Create_Dir(self, dir_name):\n",
    "        if not os.path.exists(\"data\"):\n",
    "            try:\n",
    "                os.mkdir(\"data\")\n",
    "                print(\"Created directory 'data'\")\n",
    "            except:\n",
    "                print(\"Unable to create directory 'data': Directory already exists\")\n",
    "        else:\n",
    "            print(\"Unable to create directory 'data': Directory already exists\")\n",
    "\n",
    "        if not os.path.exists(\"data/data_\" + dir_name):\n",
    "            try:\n",
    "                os.mkdir(\"data/data_\" + dir_name)\n",
    "                print(\"Created directory 'data/data_\" + dir_name + \"'\")\n",
    "            except:\n",
    "                print(\"Unable to create directory 'data/data_\" + dir_name + \"': Directory already exists\")\n",
    "        else:\n",
    "            print(\"Unable to create directory 'data/data_\" + dir_name + \"': Directory already exists\")\n",
    "\n",
    "        if not os.path.exists(\"data/data_\" + dir_name + '/img'):\n",
    "            try:\n",
    "                os.mkdir(\"data/data_\" + dir_name + '/img')\n",
    "                print(\"Created directory 'data/data_\" + dir_name + \"/img'\")\n",
    "            except:\n",
    "                print(\"Unable to create directory 'data/data_\" + dir_name + \"/img': Directory already exists\")\n",
    "        else:\n",
    "            print(\"Unable to create directory 'data/data_\" + dir_name + \"/img': Directory already exists\")\n",
    "\n",
    "    def Scrape_Instagram(self, tag, limit=20, browser='chrome'):\n",
    "        self.Create_Dir(tag)\n",
    "\n",
    "        print(\"Starting Scrapping Instagram\")\n",
    "        file_path = \"data/data_\" + tag\n",
    "        keyword = tag\n",
    "        # Adding path.\n",
    "        if not os.getcwd() in os.get_exec_path():\n",
    "            # print('adding path')\n",
    "            if platform.system() == \"Windows\":\n",
    "                os.environ[\"PATH\"] = os.environ[\"PATH\"] + \";\" + os.getcwd()\n",
    "            else:\n",
    "                os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + os.getcwd()\n",
    "\n",
    "        # opening instagram in browser\n",
    "        \n",
    "        #if 'chrome' in browser.lower():\n",
    "        #    driver = webdriver.Chrome()\n",
    "        #else:\n",
    "        #    driver = webdriver.Firefox()\n",
    "        \n",
    "        driver = webdriver.Chrome('../chromedriver')\n",
    "        driver.get(\"https://www.instagram.com/\" + \"explore/tags/\" + tag)\n",
    "\n",
    "        print(\"Loading Posts\")\n",
    "        time.sleep(10)\n",
    "        print(\"Loading Data\")\n",
    "\n",
    "        # Clicking on load more once to load more images. Afterwards we will just\n",
    "        # tap space to scroll to the page end to load more images\n",
    "        actions = ActionChains(driver)\n",
    "        actions.send_keys(Keys.SPACE).perform()\n",
    "        actions.send_keys(Keys.SPACE).perform()\n",
    "        actions.send_keys(Keys.SPACE).perform()\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Just tap space to scroll to the page end to load more images\n",
    "        clear = lambda: os.system('cls')\n",
    "        msg = \"Loading Images\"\n",
    "        class_div_img = [\"_si7dy\"]\n",
    "        for div in class_div_img:\n",
    "            if len(driver.find_elements_by_class_name(div)) > 1:\n",
    "                while (len(driver.find_elements_by_class_name(div)) ) <= limit :\n",
    "                    actions.send_keys(Keys.SPACE).perform()\n",
    "                    msg = msg + \".\"\n",
    "                    print(msg)\n",
    "                    print(len(driver.find_elements_by_class_name(div)))\n",
    "                    time.sleep(2.5)\n",
    "                    if len(msg) > 18:\n",
    "                        msg = \"Loading Images\"\n",
    "        print(str(limit) + \" images loaded\")\n",
    "\n",
    "        # Storing images links and captions. Slicing with 9 because first 9 posts\n",
    "        # are the 'most popular' posts for that tag\n",
    "        img_src = []\n",
    "        img_caption = []\n",
    "        hashtags = {}\n",
    "\n",
    "        for data in driver.find_elements_by_class_name(\"FFVAD\"):\n",
    "            #     u.get_attribute(\"href\").split(\"/\")[4]\n",
    "            img_caption.append(data.get_attribute(\"alt\"))\n",
    "            img_src.append(data.get_attribute(\"src\"))\n",
    "\n",
    "        img_caption = img_caption[9:limit + 9]\n",
    "        img_src = img_src[9:limit + 9]\n",
    "        img_caption.sort()\n",
    "\n",
    "        # Create a workbook for excel\n",
    "        tag_File = file_path + \"/\" + tag + \"_Instagram.xlsx\"\n",
    "        wb = openpyxl.Workbook()\n",
    "        ws_Captions = wb.create_sheet(title=\"Caption\")\n",
    "        col = 'A'\n",
    "        row = 1\n",
    "\n",
    "        print(\"Dumping data in excel file\")\n",
    "        for caption in img_caption:\n",
    "            tags = caption.split(\"#\")\n",
    "            # write caption to excel file\n",
    "            ws_Captions[col + str(row)] = tags[0]\n",
    "            row += 1\n",
    "\n",
    "            # strip tags\n",
    "            tags = tags[1:]\n",
    "            for tag in tags:\n",
    "                cleaned = tag.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "                cleaned = cleaned.lower()\n",
    "                if cleaned not in hashtags and len(cleaned) < 20:\n",
    "                    hashtags[cleaned] = 1\n",
    "                elif cleaned in hashtags and len(cleaned) < 20:\n",
    "                    hashtags[cleaned] = hashtags[cleaned] + 1\n",
    "\n",
    "        # sort hashtags with frequencies and store them in excel\n",
    "        hashtags = sorted(hashtags.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "        ws_Tags = wb.create_sheet(title=\"Tags\")\n",
    "        tagName = 'A'\n",
    "        tagFreq = 'B'\n",
    "        row = 1\n",
    "\n",
    "        for tag in hashtags:\n",
    "            ws_Tags[tagName + str(row)] = tag[0]\n",
    "            ws_Tags[tagFreq + str(row)] = tag[1]\n",
    "            row += 1\n",
    "\n",
    "        wb.save(tag_File)\n",
    "\n",
    "        print(\"Dumping Images. This will take some time!\")\n",
    "        row = 1\n",
    "        for src in img_src:\n",
    "            urllib.request.urlretrieve(src, file_path + '/img/Instagram_' + str(row) + \".jpeg\")\n",
    "            row += 1\n",
    "            if (row % 10 == 0):\n",
    "                print(\"(\" + str(row) + \"/\" + str(len(img_src)) + \") Images Downloaded\")\n",
    "\n",
    "        print(\"Closing Instagram\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Social Media Scrapper...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter keyword to search for:  espaciosya\n",
      "Enter how many posts to scrape from Instagram:  10\n",
      "Enter how many posts to scrape from Twitter:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to create directory 'data': Directory already exists\n",
      "Created directory 'data/data_espaciosya'\n",
      "Created directory 'data/data_espaciosya/img'\n",
      "Starting Scrapping Instagram\n",
      "Loading Posts\n",
      "Loading Data\n",
      "10 images loaded\n",
      "Dumping data in excel file\n",
      "Dumping Images. This will take some time!\n",
      "Closing Instagram\n",
      "Stopping Social Media Scrapper...\n"
     ]
    }
   ],
   "source": [
    "#from src.InstagramScrapper import InstagramScrapper\n",
    "#from src.TwitterScrapper import TwitterScrapper\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"Starting Social Media Scrapper...\")\n",
    "    keyword = str(input(\"Enter keyword to search for: \"))\n",
    "    insta_limit = int(input(\"Enter how many posts to scrape from Instagram: \"))\n",
    "    #twitter_limit = int(input(\"Enter how many posts to scrape from Twitter: \"))\n",
    "\n",
    "    consumerKey = 'Y2x9rnSVirom9p4aP4j4GmWGy'\n",
    "    consumerSecret = 'peCyxeqB68YvMrcdjXilHbzbWe3KXZKD4cE6NzHnjxTd2GCm9u'\n",
    "    accessToken = '2186053585-zX6VlzWtTr9nNg72SXk9q0TWe6yV6VDyI0TCaxF'\n",
    "    accessTokenSecret = 'T3NAV6vXeOzHXLwBRulUXyBxRQUP8cjdbepFkeFzQyMgh'\n",
    "\n",
    "\n",
    "    scrapper = InstagramScrapper()\n",
    "    driver = webdriver.Chrome('../chromedriver')\n",
    "    scrapper.Scrape_Instagram(tag=keyword,\n",
    "                              limit=insta_limit,\n",
    "                              browser=driver) # 'chrome' or 'firefox'\n",
    "\n",
    "\n",
    "    #twitter = TwitterScrapper()\n",
    "    #twitter.Scrape_Twitter(Consumer_Key=consumerKey,\n",
    "    #                       Consumer_Secret=consumerSecret,\n",
    "    #                       Access_Token=accessToken,\n",
    "    #                       Access_Token_Secret=accessTokenSecret,\n",
    "    #                       tag=keyword,\n",
    "    #                       limit=twitter_limit,\n",
    "    #                       lang='en')  # Language codes: https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\n",
    "\n",
    "\n",
    "    print(\"Stopping Social Media Scrapper...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hashtags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-918e6379e1ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhashtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hashtags' is not defined"
     ]
    }
   ],
   "source": [
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
